# Absolut-Network

Ein paar Einstellugen im call sollte ich villeicht erkl√§ren:

+set_absolute : Applies abs() on the kernel and bias of each layer. (if on)

+use_activation_shift : Umschlag Punkt der relu aktivierung elementweise verschiebbar. (if on)

+check_positive_constraint : raises Error if a negative value is encountered along the way. (if on)
